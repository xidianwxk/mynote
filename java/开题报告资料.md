# 基于MSVL的卷积神经网络建模框架的设计与实现



### 选题来源

国家自然科学基金项目

### 中文摘要

本文对卷积神经网络的形式化建模方法进行研究，旨在为神经网络系统进行形式化验证提供模型理论基础。人工智能系统在近年来不断发展，应用于许多安全攸关的领域，这也就引起了许多对于神经网络系统可信性的研究。本文以建模仿真语言MSVL以及投影时序逻辑PTL为基础，对卷积神经网络的结构与行为进行形式化建模研究，构建一套卷积神经网络验证的基础模型框架，从而为卷积神经网络的形式化验证提供建模基础，并进一步为其他类型的深度学习框架的形式化建模提供理论基础。

## 选题依据

### 选题意义

机器学习和人工智能系统越来越广泛地被应用于各种领域中，在传统技术难以达到高效的图像识别、自然语言处理、声音识别等领域达到了接近人工的能力。然而近年来，以神经网络为代表的人工智能系统被大量应用于医药、金融、交通、国防、电力等安全攸关的领域，这也就对于人工智能系统的可信性提出了更高的要求。

目前，国内外人工智能系统的可信性研究大都在对神经网络系统的安全性进行研究，尤其是对抗性样本领域的研究，这是因为对抗性样本会在输入中加入一个噪声，从而导致结果以高置信度输出错误结果，严重的影响了神经网络的性能。近年来，也存在许多以此特性对神经网络的攻击。此外，自动驾驶技术作为深度学习的热点，研究工作也仍在推进，以19年自动驾驶排名第一的谷歌Waymo为例，在2019年1月到2020年9月的路测中，Waymo共驾驶里程10万公里，发生了47起交通事故，其中有几起事故是由于自动驾驶车撞到障碍物或误判导致的追尾。近年深度学习在医疗辅助诊断的应用也在扩展，而对于核磁共振图像中人类难以察觉的扰动，该系统却可能产生误诊。

传统的形式化分析与验证方法一般研究的是具有严格的逻辑描述或结构化的描述的软硬件系统，而作为以连接为基础构造、并用优化算法来更新参数的神经网络系统缺乏逻辑结构，从而传统的形式化分析与验证方法难以直接应用于深度学习的可信性研究。此外，神经网络系统是数据驱动的系统，需要大量的数据来进行计算，这给神经网络的建模研究提出了更大的挑战。

形式化验证基础是建模，目的是验证系统是否满足预期性质，一方面是建立严格的形式化模型，另一方面是将性质刻画为时序逻辑公式，从而能够采用模型检测或定理证明来确定，所以说形式化验证很重要的一个环节是对于系统进行建模。当前实验室已经有基于MSVL的构建全连接神经网络模型的框架，本文将会在此基础上进行扩展，构建卷积神经网络的建模框架。

### 国内外研究现状

对人工智能系统进行可信性验证近年来是国内外相关研究的重点，但目前为止，国内外都未形成统一的标准。人工智能系统的“安全危机”主要包含了数据质量、可解释性、内部运算不可控、系统性太不可靠等问题。由于人工智能系统的设计和开发都是由数据驱动的，所以核心问题是如何保证数据的安全性。

近些年来，安全领域研究重点更多的放在对抗性技术上，对抗性攻击研究方面主要分为几类，首先是使用损耗函数梯度的攻击技术，然后是以JSMA为代表的使用输出梯度的攻击技术，以及直接生成优化问题的攻击技术如DeepFool和C&W攻击技术。这些攻击技术基于不同的生成方式来生成对应神经网络的对抗性样本，从而为神经网络的健壮性提供反例。同样的，对抗性防御领域也有许多的进展，如由goodfellow提出的对抗性训练方法即用对抗性样本重新训练模型，尽管基于小批量样本进行，但是仍然会导致网络的不稳定；Dhillon提出的激活转换方法则调整了隐藏层的激活函数来随机删除节点，并按比例扩展剩下的节点以保留激活的动态范围，同时应用SAP来提高鲁棒性；Feinman等人则提出了一种识别对抗区域的特征的方法，从而能够预先判断输入是否是对抗性输入，以预先避免对抗性样本。但是很多对抗性防御的方法都存在漏洞，会给网络在自然样本上的识别带来不利影响，而另一类防御技术则能够为防御技术提供保证，称之为带保证的对抗防御，比如Hein和Andriushchenko提出的正规化训练方法，通过稳定分类器函数在数据点处的差异来保证鲁棒性，但是却不能保证可达性。此外，新加坡国立大学的梁振凯团队进一步研究了神经网络的反演技术，这种技术能够从预测结果中反向推出网络的输入，在对亚马逊人工识别开放系统中的实验表明，这种技术能够反演出目标用户的人脸图像，从而能达到窃取用户隐私的目的。

在安全性方面，Huang等人将健壮性、输出可达性、区间性质和利普希茨属性等性质逻辑公式化，用这四条属性作为神经网络的安全性验证的初步。对于以上Huang等人提出的性质性质，国内外已有许多研究团队给出了一些解决方案。Narodytska等人则提出了简化布尔可满足性来验证二值化神经网络的性质，其中权重和激活也是二进制的，这种布尔编码特别适合于验证图像分类中的中型DNN的健壮性。而G.Katz等人在2017年提出了Reluplex作为SMT求解器，继承了Simplex算法中的规则，专为ReLU操作添加了一些规则，先求线性约束的解，然后用ReLU规则来满足每个节点的ReLU关系，主要解决以ReLU为激活函数的网络。此外，Lomuscio等人以整数线性规划来研究神经网络的性质，根据前向传播公式与激活函数对每一层的求和值进求极值，从而得到在特定条件下网络内各层的情况，得到其性质。

而目前为主国内外的研究缺少对于神经网络全局性的建模，大都是基于神经网络的部分局部简化假设进行的验证工作，主要集中于神经网络的健壮性与对抗性样本的存在性，缺乏全局细致的模型与验证技术。而实验室已经有了对于全连接神经网络建模工作的积累，在此基础上进一步扩展这个模型，对于卷积神经网络的结构与行为进行综合的建模，为卷积神经网络提供更系统、更细致的模型，将为神经网络全局性的性质验证提供基础，建模神经网络的各种行为，从而能够验证更多性质，例如隐私性和与训练相关的性质等。

## 研究方案

### 研究目标

对卷积神经网络的形式化建模进行研究，在已有工作的基础上进一步探索神经网络形式化建模方法，能够对神经网络的训练与测试进行综合性建模。开发卷积神经网络建模工具，可由用户自定义卷积神经网络相关参数，生成神经网络的综合性形式化模型。

###  研究内容

基于形式化语言MSVL与已完成的BP神经网络建模的部分工具，本研究的主要内容包括：

1. 对卷积神经网络中层次结构的形式化建模；
3. 对卷积神经网络预测与训练行为进行形式化建模；
5. 使用MSVL语言实现建模框架；
6. 通过实例对性质验证进行探索；
7. 为本系统创建一种良好的用户界面。

### 拟解决的关键问题

1. 如何利用基于MSVL对卷积层与池化层进行形式化建模；
2. 如何对卷积神经网络的性质进行探索和逻辑刻画。

### 拟采用的研究方法、技术路线、试验方案及可行性研究

#### 研究方法

实验研究，对现有理论进行扩充，并扩展其应用范围。主要是对时序逻辑相关理论在模型检测方面进行实现，将MSVL应用于卷积神经网络的检测，用MSVL实现卷积神经网络的行为与功能。

#### 技术路线

拟采用基于投影时序逻辑PTL的MSVL语言进行卷积神经网络的建模。PTL作为一种经过验证的逻辑，具备严格的逻辑基础，而在此基础上发展起来的MSVL语言则支持多种基本类型与复合类型、函数、框架等重要机制以及顺序、并发、选择、循环等多种控制结构，可以方便的用于神经网络的建模。

卷积神经网络的形式化建模从系统层次结构出发，逐层开展，最终将各层的模型组合成为最终的模型，核心在于对于神经网络的数据结构与行为进行建模，同时为了保证模型的可扩展性，在结构中考虑内存使用，使模型能够应用于更大规模的网络，主要的技术路线为：

1. 对卷积神经网络中层次结构的形式化建模；

   1. 对卷积神经网络中卷积层的建模；

   2. 对卷积神经网络中反卷积层的建模；

   3. 对卷积神经网络中池化层的建模；

   4. 将卷积层、反卷积层与池化层包含在同一结构内进行建模，将这一结构表示为：

      ```c++
      typedef struct {
      	int ConvType;				// 0 for non, 1 for convolution, 2 for deconvolution
      	int ConvPadding;			// mode:0 for SAME ,1 for VALID
      	int ConvKSize[4];			// Convolution kernel size of this layer[batch,weight,height,channel]
      	int ConvStride[4];			// Convolution Stride[batch,weight,height,channel]
      	int AcitFuncNum;			// active function [int]
      	Mat* CPaddingFormer;		// Result of padding former layer's output  
      	Mat* ConvReConstructB;		// Re-construct tensor for convolution calculating with bias
      	Mat ConvWeight;				// Convolution kernel equivalent mat with bias
      	Mat ConvKernel;				// Convolution kernel equivalent mat
      	Mat* ConvSum;				// Result of convolution calculating
      	Mat* ConvAct;				// Activate Tensor of convolution result
      	int COutSize[4];			// Size of ConvAct
      
      	int PoolType;				// 0 for non, 1 for max, 2 for average
      	int PoolPadding;			// mode:0 for SAME ,1 for VALID 
      	int PoolKSize[4];			// Pooling Size[batch,weight,height,channel]
      	int PoolStride[4];			// Pooling Stride[batch,weight,height,channel]
      	Mat* PPaddingFormer;		// Result of padding convolution's output
      	Mat* PoolReConstruct;		// Re-construct tensor for convolution calculating with bias
      	Mat PoolKernel;				// Pool kernel for average pool calculating
      	Mat* PoolSum;				// Pool layer output
      	int OutSize[4];				// Size of PoolSum
      
      	int OutNum;					// Number of Out Channels
      }CPLayer;
      ```

2. 对卷积神经网络预测与训练行为  进行形式化建模研究  ；

   1. 对卷积神经网络的前向传播算法进行建模；
   2. 对卷积神经网络的反向传播算法进行建模；
   3. 对卷积神经网络的优化算法进行建模。

3. 使用MSVL语言实现建模框架；

4. 通过实例对性质验证进行探索；

   1. 用MSVL建模框架构建神经网络；
   2. 对于神经网络的部分性质进行定义；
   3. 在构建好的网络上进行性质验证；

5. 为本系统创建一种良好的用户界面。

   1. 用户能通过界面设置网络的自定义参数；
   2. 用户能通过界面设置网络所用到的数据集；
   3. 用户能通过界面进行网络的训练与测试并获取结果；
   4. 用户能通过界面选择预设的性质并获取验证结果；
   5. （？）用户能通过界面键入PTL性质描述并获取验证结果。

#### 试验方案

1. 查阅相关文献，学习深度神经网络基础与卷积神经网络运算相关知识；
2. 查阅相关文献，了解投影时序逻辑与建模语言MSVL相关理论知识；
3. 了解部分神经网络开发框架中对于卷积神经网络相关运算进行的优化；
4. 找数据集并用MSVL以此搭建卷积神经网络模型。

#### 可行性分析

1. 论文《MSVL a Typed Language for Temporal Logic Programming》使用逻辑定义了一种编程语言，对常用的数据类型，顺序，条件，循环结构等进行了严格的逻辑定义，并开发了一套程序语言 MSVL。
2. 论文《Full Regular Temporal Property Verification as Dynamic Program Execution》提出了一种程序可动态执行统一模型检测方法，同时开发了统一模型检测器 UMC4MSVL；
3. 论文《A compiler for MSVL and its applications》基于 LLVM 完成一 个 名为 MC 的编译器服务于建模仿真验证语言 MSVL，同时分析了 MC 应用于人工智能 AI 的可行性。

#### 研究计划与预期取得的成果

| 时间节点        | 预期研究成果                                               |
| --------------- | ---------------------------------------------------------- |
| 2021.03-2021.05 | 了解投影时序逻辑PTL                                        |
| 2021.05-2021.06 | 研究MC编译器，了解MSVL相关编程技术                         |
| 2021.06-2021.08 | 了解卷积神经网络相关知识与主流框架                         |
| 2021.08-2021-11 | 完成卷积神经网络的前向传播建模工作                         |
| 2021.11-2022.02 | 完成卷积神经网络的反向传播建模工作                         |
| 2022.02-2022.04 | 完善设计流程，改善框架结构，测试并验证该模型的分类回归性能 |
| 2022.04-2022.05 | 撰写论文                                                   |

### 研究基础

#### 已具备的实验条件与研究工作积累

1. 研究条件：MC编译器、C2MSVL转换器、UMC4MSVL验证器。
2. 研究工作积累：实验室有一套完整的PTL模型理论及MSVL开发相关工作，并且在此基金项目上已经有了之前的全连接神经网络的建模工作。目前已通过学习基本了解了MSVL语言与PTL投影时序逻辑的相关内容，也查阅了卷积神经网络的部分资料与内容，有了一定的认识。实验室在之前的工作中，开发了一套基于MSVL的全连接神经网络模型框架，并已经有了对着这套系统的了解，将基于这个框架进行进一步的开发。